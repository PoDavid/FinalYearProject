'''

This module serves as preprocess of the data that are going to be put into the neural networks.
The generated data would be stored into npy files and waiting to extracted by the rnn files.
This module also heavliy depends on comly.py

There are mainly two most important functions so far, 

format_interfere, which is responsible for extracting the interfere data and put it into numpy array

AP_connections, which get the connection, disconnection and roaming data output it as numpy array format.

'''


import numpy as np
import comlo
import time
import json
import argparse
from multiprocessing import Process

##################
# settings 

AP_num = 1000
period_duration = 120
flatten = True
stored_info = [ 'connected', 'disconnected', 'roam in', 'roam out' ]

##################
	
def read_dis(read_path_mac):

	# { Mac : [ cur_pos, [ APID, dis, APID, dis ]] ... }

	all_mac = {}
	i = 0
	fr = comlo.terfread( read_path_mac )
	for line in fr:
		line_b = line.split(':')
		Mac_name = line_b[0]

		# flatten nested list designed by the addClient module
		serie = [ i for j in line_b[1].split(',') for i in j.split('-') if i != '' ]
		all_mac[ Mac_name ] = [ 0, serie ]
			
	print('Total Mac address number : ' + str(len(all_mac) ) )

	return all_mac
	
def format_interfere( read_path, mapping_file ):
	'''
	to make a one hot series storing interfere for every time period,
	how many interfere happen for each APID.
	
	In the mapping file, there should a a dictionary storing the mapping from the mac address of ap to theire apid.
	the mapping_file should be generated by map_ap_to_mac.py
	
	'''
	global AP_num, period_duration
	
	the_dict = json.load( open(mapping_file,'r') )

	last_time = -1
	sec_count = period_duration - 1
	
	big_list = []
	big_arr = np.zeros( (AP_num,) , dtype=np.int8 )
	
	# to record the number of mac that are not able to be convert into apid
	kerr = 0
	kok = 0
	
	with comlo.terfread( read_path ) as log_file:
		for line in log_file:
			if 'AP detected interfere' in line:
				
				# checksum is actually checking the time
				t = comlo.checktsum( line )
				if t > last_time:
					last_time = t
					sec_count += t - last_time

					# we may face the situation that the time differed too much
					while sec_count >= period_duration:
						big_list.append( big_arr )
						big_arr = np.zeros( (AP_num,) , dtype=np.int8 )
						gen_count += 1
						sec_count -= period_duration
				
				try:
					line_d = line.split( 'APMAC' )[1].replace( ':', '' ).replace( '\n', '' )
					big_arr[ int( the_dict[ line_d ] ) ] += 1
					kok += 1
				except KeyError:
					kerr += 1
				
		# have to append the last array
		big_list.append( big_arr )
	
	# the first np array is actually empty one, so delete it
	np.save('Inte_1118', np.asarray( big_list[1:] ) )
	
	print( kerr )
	print( kok )

def gen_array():
	global AP_num, stored_info, flatten
	if flatten:
		return np.zeros( ( AP_num*len(stored_info) ), dtype=np.int8 )
	else:
		return np.zeros( ( AP_num,len(stored_info) ), dtype=np.int8 )
		
def AP_connections(read_path, read_path_mac):
	'''
	to make a one hot series storing for every time period,
	how many connection, disconnection and roam in, roam out happen for each APID.
	'''


	
	huge_array = []
	one_period = None
	current_time = None
	all_mac = read_dis(read_path_mac)
	
	sec_count = period_duration - 1
	gen_count = 0
	
	lst = len(stored_info)
	
	fr = comlo.terfread( read_path )
	for line in fr:
		#print('in')
		line_d = line.split(',')

		# check if the time change, if so, the data should be store to next np array
		if current_time != line_d[0]:
			sec_count += comlo.time_change( current_time, line_d[0] )
			current_time = line_d[0]
			
			while sec_count >= period_duration:

				huge_array.append( one_period )
				one_period = gen_array()
				gen_count += 1
				sec_count -= period_duration
			

		if line_d[5] == 'jn':
			APID = line_d[ 7 ]
			all_mac[ line_d[ 4 ] ][0] += 1
			
			if flatten:
				one_period[ int(APID)*lst ] += 1
			else:
				one_period[ int(APID) ][ 0 ] += 1
			
		elif line_d[5] == 'rm':
			APID = line_d[ 7 ]
			leave_APID = line_d[ 10 ]
			
			if flatten:
				one_period[ int(APID)*lst + 2 ] += 1
				one_period[ int(leave_APID)*lst + 3 ] += 1				
			else:
				one_period[ int(APID) ][ 2 ] += 1
				one_period[ int(leave_APID) ][ 3 ] += 1
			
			all_mac[ line_d[ 4 ] ][0] += 2
		
		elif line_d[5] == 'dis':
			try:
				temp_mac = line_d[ 4 ]
				
				# get current position, get current status, and make sure it matches.
				inx = all_mac[ temp_mac ][0]
				cur_status = all_mac[ temp_mac ][ 1 ][ inx ]
				assert cur_status.startswith('dis')
				
				if flatten:
					one_period[ int( all_mac[ temp_mac ][ 1 ][ inx - 1 ] )*lst + 1 ] += 1
				else:
					# Here we use inx-1 since the front of the sequence is earlier
					one_period[ int( all_mac[ temp_mac ][ 1 ][ inx - 1 ] ) ][ 1 ] += 1
				
			except AssertionError as err:
				print('assertion error, disconnected status unmatched')
				print(temp_mac)
				print('inx : ' + str(inx) + ' cur_status : ' + str(cur_status) )
				print(all_mac[ temp_mac ][ 1 ])
				break
			except IndexError:
				pass
				# print( 'disconnected source not found' )
			except ValueError:
				# raise from ```one_period[ int( all_mac[ temp_mac ][ 1 ][ inx - 1 ] ) ][ 1 ] += 1```
				# since if ```all_mac[ temp_mac ][ 1 ][ inx - 1 ]``` is dis, it would break
				if inx == 0:
					pass
				
				else:
					# seem it's not a bug of the program, the disconnection really appear twice
					pass
					'''
					print( 'double disconnected' )
					print( temp_mac + ' inx : ' + str(inx) )
					print( all_mac[ temp_mac ][ 1 ] )
					
					import time
					time.sleep(0.5)
					'''
			finally:
				all_mac[ line_d[ 4 ] ][0] += 1
				
	print('Num of period generated : ' + str(gen_count))
	
	# have to append the last array
	huge_array.append( one_period )
	
	huge_np_arr = np.asarray( huge_array[1:] )
	
	np.save('AP_1118f120s', huge_np_arr)

def main():

	parser = argparse.ArgumentParser(description='Format the data.')
	parser.add_argument('--apc', action='store_true', help='use AP_connections function')
	parser.add_argument('--intere', action='store_true', help='use format_interfere function')
	
	args = parser.parse_args()

	if args.apc:
		AP_connections('1118wx/infocsv' ,'1118wx/client_routec')
	
	if args.intere:
		format_interfere( '1118wx/comf' ,'map_aps_simp.json' )
	
if __name__ == '__main__':
	main()

	
	
	